---
layout: post
title:  Quantifier l'incertitude pour am√©liorer les performances de spaCy
date:   2020-07-31
image:  /assets/img/2020-07-31/model_confidence.png
tags:   [Incertitude, NER, spaCy, Probabilit√©]
lang:   üá´üá∑ Lire en fran√ßais
ref:    spacy
hide:   true
---

Dans cet article, nous allons voir comment la recherche d'incertitude d'un mod√®le assez complexe permet d'augmenter 
la pr√©cision de mani√®re substantielle ainsi que la satisfaction de l'utilisateur final face √† un syst√®me 
d'apprentissage supervis√©.

Les sujets seront d√©taill√©s dans l'ordre suivant : contexte et premi√®re solution retenue, choix du mod√®le 
[NER](https://fr.wikipedia.org/wiki/Reconnaissance_d%27entit%C3%A9s_nomm%C3%A9es) (Reconnaissance d'Entit√©s Nomm√©es), 
analyse des erreurs et enfin quantification d'incertitude pour am√©liorer les r√©sultats. Les donn√©es pr√©sent√©es 
ne sont pas celles du projet pour des raisons de confidentialit√©.


# Introduction

Dans un r√©cent projet, j'ai eu comme objectif l'extraction d'information depuis un corpus de documents PDF. Apr√®s 
la lecture rapide d'une dizaine de documents, il s'est av√©r√© que plusieurs champs recherch√©s suivaient un 
motif r√©currents assez simple. Cela a permis la cr√©ation un premier mod√®le tr√®s simple bas√© sur des [expressions 
r√©guli√®res](https://fr.wikipedia.org/wiki/Expression_r%C3%A9guli%C3%A8re). Le pipeline √©l√©mentaire suivant valide 70% 
des objectifs :

- Convertir le PDF en fichier texte avec pdftotext

- Effectuer quelques t√¢ches de nettoyage (caract√®res sp√©ciaux, lemmatisation)

- Rechercher les motifs r√©currents (par exemple "date de fermeture :")

- Extraire l'entit√© d'inter√™t qui suit le motif :

    1. Soit avec une expression r√©guli√®re (pour une date contenue dans la variable *text* : 
    `re.findall(r'(\d+/\d+/\d+)', text)`)
    
    2. Soit avec une table de correspondance (recherche d'un match entre la table et les N caract√®res suivant le motif)

Pour finaliser un premier rendu applicatif associ√© √† ce pipeline, j'ai choisi [streamlit](
https://www.streamlit.io/) - un projet qui permet de cr√©er rapidement un rendu dans le 
navigateur. Les quelques lignes de code ci-apr√®s affichent une page ou l'on peut t√©l√©verser un document 
PDF et voir le r√©sultat du mod√®le.

```python
import streamlit as st

st.title('Extracteur d\'information')
pdf_file = st.file_uploader('', type=['pdf'])
show_file = st.empty()
if not pdf_file:
    show_file.info('S√©lectionnez un PDF √† traiter.')

base64_pdf = base64.b64encode(pdf_file.read()).decode('utf-8')
pdf_display = f'<embed src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf">'
st.markdown(pdf_display, unsafe_allow_html=True)

pdf_text = _convert_pdf_to_text_and_clean(pdf_file)
predictions = _run_model(pdf_text)

show_file.info(f"""Titre : {predictions['title']}
                   Date : {predictions['date']}""")
pdf_file.close()
```

![]({{site.baseurl}}/assets/img/2020-07-31/app_empty.png)
*Figure 1 : Rendu applicatif avec streamlit*

![]({{site.baseurl}}/assets/img/2020-07-31/app_uploaded.png)
*Figure 2 : Aper√ßu du PDF et des pr√©dictions*

En plus de rendre la t√¢che ais√©e, la communaut√© streamlit est active comme l'illustre la r√©solution 
du [probl√®me rencontr√©](https://github.com/streamlit/streamlit/issues/1088) pour afficher le PDF.

Les deux conclusions de cette premi√®re partie sont - non pour me d√©plaire - devenues prosa√Øques : en d√©but de 
projet, les id√©es les plus na√Øves apportent le plus de valeur et les outils de la communaut√© du 
logiciel libre sont admirables.


# Le mod√®le NER

Certains champs √† extraire pr√©sentent une plus grande complexit√©. Une simple analyse statistique ne permet pas de 
trouver de motif r√©ccurent. Ils ne se trouvent ni √† une place d√©finie dans le texte ni n'ont de structure 
particuli√®re. Quelques recherches sur internet nous guident rapidement vers les mod√®les de reconnaissance d'entit√©s 
nomm√©es [NER](https://fr.wikipedia.org/wiki/Reconnaissance_d%27entit%C3%A9s_nomm%C3%A9es) qui permettent gr√¢ce √† 
l'apprentissage supervis√© d'associer des mots √† des √©tiquettes.

Plusieurs librairies impl√©mentent des surcouches facilitant la prise en main des mod√®les pour l'entra√Ænement et 
l'inf√©rence. J'ai opt√© pour [spaCy](https://spacy.io/usage/linguistic-features#named-entities) qui met en avant 
son ergonomie et ses performances temporelles (~2h par entra√Ænement sur un CPU 16 coeurs). Pour plus de 
d√©tails quant au fonctionnement du mod√®le, il convient de se r√©f√©rer √† la documentation, en particulier √† 
[cette vid√©o](https://spacy.io/universe/project/video-spacys-ner-model). 

Le dataset contient 3,000 documents partiellement annot√©s. Partiellement signifie ici que tous les champs cherch√©s ne 
sont pas annot√©s, en revanche lorsqu'un champ est annot√©, il l'est sur la totalit√© du dataset. L'annotation a 
√©t√© effectu√©e de fa√ßon automatique en parcourant le code HTML de pages web ([scrapping](
https://fr.wikipedia.org/wiki/Web_scraping)). Comme strat√©gie de validation crois√©e j'ai retenue un d√©coupage 
avec 2,100 documents pour l'entra√Ænement et 900 pour la validation. La pr√©cision recherch√©e est de l'ordre 
de 95% pour chaque champ.

Ci-apr√®s se trouve un exemple du format d'entr√©e attendu :
```python
TRAIN_DATA = [
    ("Horses are too tall and pretend to care about your feelings",
     {"entities": [(0, 6, "ANIMAL")]}),
    ("Who is Shaka Khan?",
     {"entities": [(7, 17, "PERSON")]}),
    ("I like London and Berlin.",
     {"entities": [(7, 13, "LOC"), (18, 24, "LOC")]}),
]
```

On remarque que chaque exemple est constitu√© d'un texte suivi de son √©tiquette d√©limit√©e par deux 
indices, celui de d√©but et celui de fin. Les PDFs de notre base de donn√©es donnent des textes trop grands pour 
tenir dans la RAM. Une astuce pratique consiste √† diviser le texte en morceaux. N√©anmoins cela cr√©√© beaucoup 
d'exemples sans label (beaucoup de morceaux n'ont aucune entit√© d'int√©r√™t). On qualifie le dataset de 
creux. Une fonction de r√©√©quilibrage permet de pallier ce probl√®me en s√©lectionnant un √©chantillon sans 
label avec une probabilit√© assez faible.

```python
def _balance(data):
    balanced_data = [row for row in data if len(row[1]['entities']) > 0 or np.random.rand() < .1]
    return balanced_data
```

La probabilit√© $$.1$$ peut √™tre ajust√©e, l'objectif √©tant d'atteindre une proportion raisonnable d'√©chantillon 
avec √©tiquette (50% dans notre cas). L'algorithme voit ainsi passer de nombreux exemples sans annotation mais 
n'est pas satur√© par ces derniers.

Une fois les don√©es format√©es, la lectures des [scripts d'exemple](https://spacy.io/usage/training#ner) fournis permet 
de lancer l'entra√Ænement d'un premier mod√®le. J'ai effectu√© quelques modifications pr√©liminaires au code :

- factoriser et tester le code

- utiliser [click](https://click.palletsprojects.com/en/7.x/) pour les commandes

- ajouter [tqdm](https://github.com/tqdm/tqdm) pour controller l'avancement des t√¢ches chronophages

- cr√©er une fonction pour calculer notre m√©trique m√©tier √† chaque it√©ration (par d√©faut seule la *loss* est calcul√©e)

Regardons cette m√©trique de plus pr√®s. Pour qualifier les r√©sultats on se restreint dans un premier temps 
√† un unique champ (par exemple le titre du document). Ce qui int√©resse notre utilisateur est l'affichage 
du champ "titre" peu importe le nombre de fois qu'il appara√Æt ou sa position dans le PDF (cf. Figure 2). Ainsi, 
notre pr√©diction sera un vote de majorit√© par document. Si le mod√®le pr√©dit "[a, a, b]" comme √©tant des 
titres, la pr√©diction finale sera "a". On rappelle que l'objectif est d'atteindre 95% de bonnes r√©ponses.

Le premier entra√Ænement de r√©f√©rence a donn√© 67%. Apr√®s avoir coup√© les textes en morceaux, l'algorithme atteint 
72%. Enfin, le r√©√©quilibrage fait gagner 4 points de plus pour arriver √† 76% de bonnes r√©ponses.


# Analyse des erreurs

Une √©tape cruciale en statistique inf√©rentielle est l'√©tude des erreurs. Cette analyse poss√®de une double vertu : 
mieux comprendre le mod√®le et se concentrer sur ses faiblesses pour l'am√©liorer. Examinons donc les PDFs dont le 
titre n'a pas √©t√© trouv√© pour tenter d'investiguer les causes de ces b√©vues.

![]({{site.baseurl}}/assets/img/2020-07-31/error_analysis.png)
*Figure 3 : Analyse des erreurs*

On souhaite se concentrer sur les erreurs, c'est-√†-dire lorsque la colonne `found` est √† `False`. Il y a 3 erreurs 
dans la table ci-dessus :

- Indice 4 : rien en commun entre la pr√©diction et la valeur r√©elle

- Indice 3 : erreur plus subtile, le mot "of" est en trop

- Indice 1 : encore plus proche, il y a un "s" en trop

D'un point de vue m√©tier cela importe peu l'utilisateur lorsque l'erreur est petite. On peu donc construire une 
distance qui permet d'√™tre plus flexible sur l'acceptation de la pr√©diction. La fonction ci-apr√®s v√©rifie que la 
valeur pr√©dite n'est pas vide, puis accepte le r√©sultat en cas d'inclusion ou si la [distance de 
Levenshtein](https://fr.wikipedia.org/wiki/Distance_de_Levenshtein) est inf√©rieure √† 5 (valeur arbitrairement choisie).

```python
from Levenshtein import distance

def flexible_accuracy(x):
    pred, gt = x['prediction'], x['ground truth']
    return True if pred and distance(pred, gt) < 5 and (gt in pred or pred in gt) else False

df.apply(flexible_accuracy, axis=1).mean()
```

Sans n'avoir rien chang√© au mod√®le, nous passons √† une pr√©cision de 82% pour nos utilisateurs. Il reste du chemin 
√† parcourir mais quelques points ont √©t√© gagn√© sans effort.


# Quantifier l'incertitude

A ce niveau du projet, les abonnissements sont moins √©vidents. Pour la concision de l'article, je ne vais pas 
m'attarder sur les essais non ou moins fructueux, parmi lesquels on trouve le travail sur les donn√©es et les 
r√©entrainements en modifiant les hyperparam√®tres.

Dans la continuit√© de la partie pr√©c√©dente et pour mieux comprendre les r√©sultats du mod√®le, j'ai souhait√© 
quantifier l'incertitude des pr√©dictions. La facilit√© d'utilisation de la librairie a un co√ªt, on le d√©couvre 
lorsqu'on cherche √† acc√©der aux probabilit√©s. N√©anmoins, le partage de connaissances au sein de la 
communaut√© permet √† nouveau de trouver des [√©lements de r√©ponse](https://github.com/explosion/spaCy/issues/881) :

```python
def _predict_proba(text_data, nlp_model):
    proba_dict = defaultdict(list)
    for text in text_data:
        doc = nlp_model(text)
        beams = nlp_model.entity.beam_parse([doc], beam_width=16, beam_density=0.0001)
        for beam in beams:
            for score, ents in nlp_model.entity.moves.get_beam_parses(beam):
                for start, end, label in ents:
                    proba_dict[doc[start:end].text].append(round(score, 3))
    return dict(proba_dict)
```

Cette fonction retourne un score de confiance compris entre 0 et 1 pour chaque groupe de mot identifi√© comme √©tant 
un titre.

```json
{"le vrai titre du document": [1.0, 0.946, 1.0, 0.3], 
 "une appareance de titre": [0.123, 0.356, 0.65], 
 "des mots quelconques": [0.006],
 "autre chose": [0.981]}
```

Pour plus de clart√© on agr√®ge en sommant les confiances, on normalise en divisant par la somme totale et 
on trie par ordre d√©croissant. La normalisation permet de comparer les confiances entre les documents.

```json
{"le vrai titre du document": 0.605,
 "une appareance de titre": 0.211,
 "autre chose": 0.183,
 "des mots quelconques": 0.001}
```

On consid√®re naturellement le groupe de mot avec la plus grande confiance comme √©tant la meilleure 
pr√©diction. Tra√ßons la densit√© de bonnes et mauvaises pr√©dictions en fonction de l'incertitude.

![]({{site.baseurl}}/assets/img/2020-07-31/model_confidence.png)
*Figure 4 : Densit√© de pr√©dictions en fonction de l'incertitude*

Ce trac√© montre que l'incertitude est moindre lorsque les pr√©dictions sont correctes. En particulier, pour 
une confiance sup√©rieure √† $$.4$$ (39% des cas), la pr√©cision est de 99%. Voila peut-√™tre un moyen d'augmenter notre 
performance. Concentrons nous sur les confiances inf√©rieures √† $$.4$$ (61% des cas). En dessous de 
ce seuil, la pr√©cision tombe √† 72%. Une analyse minutieuse de ces faibles confiances fait appara√Ætre 
un motif : dans les 28% d'erreurs, la valeur avec la seconde plus grande confiance est souvent la bonne 
r√©ponse. Cela est vrai dans 62% des cas. En d'autres termes, 62% des 28% d'erreurs contiennent la bonne r√©ponse 
en seconde pr√©diction.

![]({{site.baseurl}}/assets/img/2020-07-31/tree.png)
*Figure 5 : R√©capitulatif sous forme d'arbre*

Il n'y a pas d'injonction √† l'utilisation de la r√©ponse pure de notre mod√®le. Le meilleur algorithme est celui 
qui est le mieux align√© avec le besoin utilisateur. Il s'av√®re ici que l'utilisateur privil√©gie la pr√©cision. 
On propose donc une r√®gle bas√©e sur la fig. 5 qui renvoie la pr√©diction lorsque la confiance est sup√©rieur au seuil, 
dans le cas contraire, il renvoie les deux pr√©dictions ayant les plus grandes confiances.

On peut calculer la pr√©cision avec laquelle l'utilisateur verra s'afficher la bonne r√©ponse parmi celles 
propos√©es :

$$\begin{eqnarray} 
Accuracy_{Conf<0.4} &=& Accuracy_{FirstChoice} + Accuracy_{SecondChoice} \\
&=& 0.72 + (1-0.72) * 0.62 \\
&=& 0.89 \\
\end{eqnarray}$$

$$\begin{eqnarray} 
FinalAccuracy &=& 0.39 * Accuracy_{Conf>0.4} + (1-0.39) * Accuracy_{Conf<0.4} \\
&=& 0.39 * 0.99 + 0.61 * 0.89 \\
&=& 0.93 \\
\end{eqnarray}$$

On atteint ainsi 93% de pr√©cision. Pur plus de rigueur il conviendrait de cr√©er un autre ensemble disjoint 
de validation et v√©rifier ces performances.


# Conclusion

Le but n'est pas tout √† fait atteint mais le gain est substantiel. Vincent Warderdam rappelle 
lucidement dans [cette pr√©sentation](https://youtu.be/Z8MEFI7ZJlA?t=662) qu'il 
est sain de "pr√©dire moins mais prudemment". Se servir de l'information d'incertitude est profitable dans une 
pl√©thore de cas d'usage. Il suffit de convenir avec l'utilisateur des conditions. Il n'aurait pas √©t√© convenable 
par exemple dans notre exemple de donner les 5 pr√©dictions les moins incertaines car l'utilisateur 
aurait eu trop d'information √† traiter.

**La transparence de l'incertitude du mod√®le est sans doute un levier pour augmenter la satisfaction des 
utilisateurs. C'est en d√©voilant ses imperfections qu'un algorithme peut gagner la confiance des utilisateurs.**

**√Ä retenir :**

- Commencer avec un premier mod√®le simple et une boucle de r√©troaction courte : que peut-on faire sans 
algorithme d'apprentissage ?

- Adapter et assouplir le mod√®le et la m√©trique au cas d'usage

- Utiliser l'incertitude :

    1. se concentrer sur les cas les plus incertains
    
    2. rester humble en informant l'utilisateur lorsque le mod√®le n'est pas confiant

**Pour aller plus loin :**

- Rechercher les nombre minimal de donn√©es √† partir duquel le mod√®le spaCy converge (pour ajouter des 
nouveaux champs)

- Essayer d'am√©liorer les performances en moyennant avec un autre mod√®le NER ([huggingface](https://huggingface.co/) 
or [allennlp](https://allennlp.org/){:target="_blank"}) lorsque la confiance est basse

- √âtudier les erreurs du point de vue de la donn√©es : probl√®me d'√©chantillonage pour les incertitudes √©lev√©es ?
